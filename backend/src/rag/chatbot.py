# chatbot.py (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
import os

from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from dotenv import load_dotenv
load_dotenv()

PERSIST_DIR = "chroma_db"

def clean_text(text: str) -> str:
    """ ì„ë² ë”©/LLMì— ë„£ê¸° ì „ì— í…ìŠ¤íŠ¸ë¥¼ UTF-8 ê¸°ì¤€ìœ¼ë¡œ ì •ë¦¬ """
    if text is None:
        return ""
    # ìœ íš¨í•˜ì§€ ì•Šì€ ìœ ë‹ˆì½”ë“œë¥¼ ëª¨ë‘ ì œê±°
    return text.encode("utf-8", "ignore").decode("utf-8", "ignore")

def get_retriever():
    """ Chroma ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” Retriever(ë¬¸ì„œ ê²€ìƒ‰ ê°œìˆ˜(k)=5)ë¥¼ ìƒì„± """
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectordb = Chroma(
        embedding_function=embeddings,
        persist_directory=PERSIST_DIR,
    )
    return vectordb.as_retriever(search_kwargs={"k": 5})


def main():
    if not os.path.exists(PERSIST_DIR):
        raise FileNotFoundError(
            f"{PERSIST_DIR} not found. Run ingest.py first to build the DB."
        )

    retriever = get_retriever()
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2,
    )

    print("ğŸ’¬ SKKU RAG chatbot ready! Type 'exit' to quit.\n")

    from langchain_core.messages import SystemMessage, HumanMessage

    while True:
        try:
            question_raw = input("You: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nBye!")
            break

        if not question_raw:
            continue
        if question_raw.lower() in {"exit", "quit"}:
            print("Bye!")
            break

        question = clean_text(question_raw)

        # 1) ë¬¸ì„œ ê²€ìƒ‰
        docs = retriever.invoke(question)

        # 2) ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ í…ìŠ¤íŠ¸ ì •ë¦¬ + í•©ì¹˜ê¸°
        context_parts = []
        for i, d in enumerate(docs):
            text = clean_text(d.page_content).replace("\n", " ")
            context_parts.append(f"[ë¬¸ì„œ {i}] {text}")
        context = "\n\n".join(context_parts)
        context = clean_text(context)

        # 3) ì‹œìŠ¤í…œ/ìœ ì € ë©”ì‹œì§€ êµ¬ì„± + ì •ë¦¬
        system_msg_raw = (
            "ë„ˆëŠ” ì„±ê· ê´€ëŒ€í•™êµì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ëŠ” ê²ƒì„ ë„ì™€ì£¼ëŠ” ì±—ë´‡ì´ì•¼.\n"
            "ì•„ë˜ 'ë¬¸ë§¥'ì— í¬í•¨ëœ ë‚´ìš©ë§Œ ì‚¬ì‹¤ë¡œ ì‚¬ìš©í•´ì„œ ëŒ€ë‹µí•´.\n"
            "ë¬¸ë§¥ì— ê´€ë ¨ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ê³ , "
            "ì„±ê· ê´€ëŒ€í•™êµ ê³µì‹ í™ˆí˜ì´ì§€ë‚˜ ê´€ë ¨ ë¶€ì²˜ì— ì—°ë½í•˜ë¼ê³  ì•ˆë‚´í•´.\n"
            "ì‚¬ìš©ìê°€ í•œêµ­ì–´ë¡œ ë¬¼ìœ¼ë©´ í•œêµ­ì–´ë¡œ, ì˜ì–´ë¡œ ë¬¼ìœ¼ë©´ ì˜ì–´ë¡œ ë‹µí•´."
        )
        system_msg = clean_text(system_msg_raw)

        user_msg_raw = (
            f"ë¬¸ë§¥:\n{context}\n\n"
            f"ì§ˆë¬¸: {question}\n\n"
            "ìœ„ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´. "
            "ë¬¸ë§¥ì— ê´€ë ¨ ë‚´ìš©ì´ ì—†ë‹¤ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´."
        )
        user_msg = clean_text(user_msg_raw)

        messages = [
            SystemMessage(content=system_msg),
            HumanMessage(content=user_msg),
        ]

        # 4) LLM í˜¸ì¶œ
        response = llm.invoke(messages)

        print("\nBot:", response.content, "\n")


if __name__ == "__main__":
    main()